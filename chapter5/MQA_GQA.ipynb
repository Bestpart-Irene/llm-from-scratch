{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-07T13:34:31.161460100Z",
     "start_time": "2025-06-07T13:34:26.158630400Z"
    }
   },
   "outputs": [],
   "source": [
    "# MQA\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "class MQA(nn.Module):\n",
    "    def __init__(self, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        assert d_model%num_heads==0, \"d_model must divisible by num_heads\"\n",
    "        self.head_dim = d_model//num_heads\n",
    "        \n",
    "        self.qeury = nn.Linear(d_model, self.d_model)\n",
    "        self.key = nn.Linear(d_model, self.head_dim) \n",
    "        self.val = nn.Linear(d_model, self.head_dim)\n",
    "        \n",
    "        self.linear = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, d_model = x.size()\n",
    "        query = self.qeury(x) \n",
    "        key = self.key(x).unsqueeze(1) # batch_size, 1,seq_len, head_dim\n",
    "        val = self.val(x).unsqueeze(1) #batch_size, 1, seq_len, head_dim\n",
    "        \n",
    "        Q = query.view(batch_size, seq_len, self.num_heads, self.head_dim).transpose(1,2)  # [batch_size, num_heads, seq_length, head_dim]\n",
    "        print(Q.size())\n",
    "        print(key.transpose(-2,-1).size())\n",
    "        # attention\n",
    "        scores = torch.matmul(Q, key.transpose(-2,-1))/ math.sqrt(d_model)\n",
    "        print(scores.size())\n",
    "        \n",
    "        scores = torch.softmax(scores,dim=-1) # batch_size, seq_len, seq_len\n",
    "        attn_output = torch.matmul(scores, val) #batch_size, num_heads, seq_len, head_dim\n",
    "        \n",
    "        attn_output = attn_output.transpose(1,2).contiguous().view(batch_size, seq_len, self.num_heads*self.head_dim)\n",
    "        \n",
    "        attn_output = self.linear(attn_output)\n",
    "        \n",
    "        return attn_output, scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:07:16.776596100Z",
     "start_time": "2025-06-07T14:07:16.714803800Z"
    }
   },
   "id": "e3005ea1d04bb5aa"
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 12, 10, 64])\n",
      "torch.Size([16, 1, 64, 10])\n",
      "torch.Size([16, 12, 10, 10])\n",
      "output is torch.Size([16, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = 16, 10, 768\n",
    "\n",
    "mqa = MQA(d_model, 12)\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "output, _ = mqa(x)\n",
    "\n",
    "print(f\"output is {output.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:07:17.609694600Z",
     "start_time": "2025-06-07T14:07:17.532428100Z"
    }
   },
   "id": "70f982079b3221bd"
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [],
   "source": [
    "class GQA(nn.Module):\n",
    "    def __init__(self, d_model, head_dim, num_q_heads, num_kv_groups=None):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.head_dim = head_dim\n",
    "        self.num_kv_groups = num_kv_groups\n",
    "        self.num_q_heads = num_q_heads\n",
    "        \n",
    "        assert num_q_heads%num_kv_groups==0, \"num_q_heads must be divisible by num_kv_groups\"\n",
    "        self.query = nn.Linear(d_model, d_model)\n",
    "        self.key = nn.Linear(d_model, num_kv_groups*head_dim)\n",
    "        self.val = nn.Linear(d_model, num_kv_groups*head_dim)\n",
    "        \n",
    "        self.out_proj = nn.Linear(d_model, d_model)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, seq_len, _ = x.size()\n",
    "        Q = self.query(x) # batch_szie, seq_len, d_model\n",
    "        K = self.key(x)   # batch_size, seq_len, num_kv_groups*head_dim\n",
    "        V = self.val(x)   # batch_szie, seq_len, num_kv_groups*head_dim\n",
    "\n",
    "        # Q*KT\n",
    "        # Q ï¼šbatch_size, num_q_heads, seq_len, head_dim\n",
    "        # K: batch_size, num_kv_groups, seq_len, head_dim\n",
    "        Q = Q.view(batch_size, seq_len, self.num_q_heads, head_dim).transpose(1,2)\n",
    "        K = K.view(batch_size, seq_len, self.num_kv_groups, self.head_dim).transpose(1,2)\n",
    "        K = torch.repeat_interleave(K, self.num_q_heads//self.num_kv_groups, 1) # batch_size, num_q_heads, seq_len, head_dim\n",
    "        \n",
    "        scores = torch.matmul(Q, K.transpose(-2,-1))/math.sqrt(head_dim)\n",
    "        # batch_size, num_q_heads, seq_len, seq_len\n",
    "        # V batch_szie, seq_len, num_kv_groups*head_dim\n",
    "        \n",
    "        V = V.view(batch_size, seq_len, num_kv_groups, head_dim).transpose(1,2)\n",
    "        V = torch.repeat_interleave(V, self.num_q_heads//self.num_kv_groups, 1) #batch_size, num_q_heads, seq_len, head_dim\n",
    "        scores = torch.softmax(scores, dim = -1)\n",
    "        \n",
    "        attn_out = torch.matmul(scores, V)\n",
    "        attn_out = attn_out.transpose(1,2).contiguous().view(batch_size, seq_len, num_q_heads*head_dim)\n",
    "        \n",
    "        output = self.out_proj(attn_out)\n",
    "        \n",
    "        return output, scores"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:44:12.959858700Z",
     "start_time": "2025-06-07T14:44:12.952039600Z"
    }
   },
   "id": "4fa533bce2a61a66"
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[[ 1.7242, -0.8726,  1.7843, -0.0254, -0.1278,  0.4328,  0.7598,\n          -0.7234],\n         [-0.6868, -0.5239,  0.2407,  0.0415, -0.2173, -0.5755, -2.3127,\n          -1.5684],\n         [-1.2079,  0.7664,  0.7790, -0.9413,  0.3961, -1.3437, -0.6679,\n          -0.3673],\n         [-1.4134, -1.2172,  0.4095,  0.1899,  0.6765,  0.1250,  1.7811,\n           1.0072],\n         [ 0.6723,  2.2872, -0.6784, -0.1038, -0.7065, -0.1860,  0.9742,\n           0.5806]],\n\n        [[-0.0546, -0.0164, -0.1714,  0.3457,  1.0806,  0.8956,  0.6793,\n           1.0495],\n         [-0.1510,  0.5340,  0.1760,  1.1213, -1.0191,  0.9075, -0.7738,\n          -0.0395],\n         [-1.0886, -0.4489, -0.8932, -1.8782,  0.9766, -0.4804, -0.3618,\n           0.6617],\n         [ 0.7188, -0.2659,  0.0598, -0.6073,  1.0099, -2.1783,  2.0350,\n          -1.0818],\n         [-0.5871, -1.5166, -0.5091,  0.4130,  0.6491, -0.0533,  2.3273,\n          -1.1284]]])"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size, num_kv_groups, seq_len, head_dim = 1,2,5,8\n",
    "num_q_heads = 4\n",
    "# batch_size, num_kv_groups, seq_len, head_dim ->\n",
    "#batch_size, num_q_heads, seq_len, head_dim\n",
    "x = torch.randn(batch_size, num_kv_groups, seq_len, head_dim)\n",
    "x[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:44:13.042704800Z",
     "start_time": "2025-06-07T14:44:13.016692600Z"
    }
   },
   "id": "be2d14afb4c11de1"
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([1, 4, 5, 8])"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.repeat_interleave(x, 2, 1).size()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:44:13.705913400Z",
     "start_time": "2025-06-07T14:44:13.675581600Z"
    }
   },
   "id": "36550bd826ee72f"
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 12, 10, 64])\n",
      "torch.Size([16, 1, 64, 10])\n",
      "torch.Size([16, 12, 10, 10])\n",
      "output is torch.Size([16, 10, 768])\n"
     ]
    }
   ],
   "source": [
    "batch_size, seq_len, d_model = 16, 10, 768\n",
    "gqa = GQA(d_model, 64 ,12, 4)\n",
    "\n",
    "x = torch.randn(batch_size, seq_len, d_model)\n",
    "\n",
    "output, _ = mqa(x)\n",
    "\n",
    "print(f\"output is {output.size()}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:44:14.770149100Z",
     "start_time": "2025-06-07T14:44:14.744205500Z"
    }
   },
   "id": "ddd1a80787fe1f43"
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "data": {
      "text/plain": "64"
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "768//12"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2025-06-07T14:43:11.826705100Z",
     "start_time": "2025-06-07T14:43:11.773347Z"
    }
   },
   "id": "eb6507069a915cfb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cfe052442a93d9dd"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
